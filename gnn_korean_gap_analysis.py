import torch
import os
import numpy as np
import pandas as pd
import networkx as nx
import matplotlib.pyplot as plt
from matplotlib import font_manager, rc
from matplotlib.lines import Line2D
import platform
import random
import glob

# ==========================================
# âš™ï¸ ì„¤ì •
# ==========================================
GRAPH_PATH = "./outputs/graph/graph_data.pt"
ENCODER_PATH = "./outputs/graph/label_encoders.pt"
DATA_DIR = "./data"
OUTPUT_DIR = "./outputs/graph/gnn"

os.makedirs(OUTPUT_DIR, exist_ok=True)

# ì „ì—­ í°íŠ¸ ë³€ìˆ˜
GLOBAL_FONT_NAME = "sans-serif"

# ==========================================
# ğŸ› ï¸ ìœ í‹¸ë¦¬í‹°
# ==========================================
def init_font():
    global GLOBAL_FONT_NAME
    system_name = platform.system()
    if system_name == 'Windows':
        candidates = [("c:/Windows/Fonts/malgun.ttf", "Malgun Gothic"), ("c:/Windows/Fonts/msyh.ttf", "Microsoft YaHei")]
    elif system_name == 'Darwin':
        candidates = [("/System/Library/Fonts/Supplemental/AppleGothic.ttf", "AppleGothic")]
    else:
        candidates = [("/usr/share/fonts/truetype/nanum/NanumGothic.ttf", "NanumGothic")]

    for fpath, fname in candidates:
        if os.path.exists(fpath):
            try:
                font_manager.fontManager.addfont(fpath)
                GLOBAL_FONT_NAME = font_manager.FontProperties(fname=fpath).get_name()
                rc('font', family=GLOBAL_FONT_NAME)
                print(f"ğŸ”¤ ì‹œê°í™” í°íŠ¸ ë¡œë“œ: {GLOBAL_FONT_NAME}")
                break
            except: continue
    plt.rcParams['axes.unicode_minus'] = False

def load_resources():
    print("ğŸ”„ ë¶„ì„ ë¦¬ì†ŒìŠ¤ ë¡œë“œ ì¤‘...")
    try:
        data = torch.load(GRAPH_PATH, map_location='cpu', weights_only=False)
        encoders = torch.load(ENCODER_PATH, weights_only=False)
    except TypeError:
        data = torch.load(GRAPH_PATH, map_location='cpu')
        encoders = torch.load(ENCODER_PATH)
    print("âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ!")
    return data, encoders

def get_korean_brands():
    korean_file = os.path.join(DATA_DIR, "í•œêµ­_DATA.xlsx")
    if not os.path.exists(korean_file):
        files = glob.glob(os.path.join(DATA_DIR, "*í•œêµ­*.xlsx"))
        if not files: return set()
        korean_file = files[0]
    
    df = pd.read_excel(korean_file)
    target_col = 'ìƒí‘œëª…ì¹­' if 'ìƒí‘œëª…ì¹­' in df.columns else df.columns[0]
    brands = df[target_col].dropna().astype(str).unique()
    return set(brands)

# ==========================================
# ğŸ§  [NEW] ë‹¤ì–‘ì„± ê¸°ë°˜ ë¸Œëœë“œ ì„ ì •
# ==========================================
def get_diverse_top_korean_brands(data, encoders, top_k=5):
    """
    [ì„ ì • ê¸°ì¤€ ë³€ê²½]
    ë‹¨ìˆœíˆ ì „ì²´ 1~5ë“±ì„ ë½‘ëŠ” ê²Œ ì•„ë‹ˆë¼,
    'ì£¼ìš” ì‚°ì—…êµ°(Class)' ë³„ë¡œ 1ë“± ë¸Œëœë“œë¥¼ í•˜ë‚˜ì”© ë½‘ìŠµë‹ˆë‹¤.
    (ì˜ˆ: ì „ì 1ë“±, í™”ì¥í’ˆ 1ë“±, ì‹í’ˆ 1ë“±, íŒ¨ì…˜ 1ë“±...)
    """
    print("\nğŸ” í•œêµ­ ë¸Œëœë“œ ì‚°ì—…ë³„ ëŒ€í‘œì£¼ì ì„ ë³„ ì¤‘...")
    
    korean_brands_set = get_korean_brands()
    comp_names = encoders['company_classes']
    class_names = encoders['class_classes']
    
    # í•œêµ­ ë¸Œëœë“œ ì¸ë±ìŠ¤ í•„í„°ë§
    korean_indices = [i for i, name in enumerate(comp_names) if name in korean_brands_set]
    if not korean_indices: return []

    # 1. ë¸Œëœë“œë³„ ì£¼ë ¥ Class ê³„ì‚° (Sparse Matrix í™œìš©)
    # (Brand -> Trademark) * (Trademark -> Class) = (Brand -> Class Count)
    
    # í–‰ë ¬ A: Brand -> Trademark
    edge_ct = data['company', 'files', 'trademark'].edge_index
    n_comp = len(comp_names)
    n_tm = data['trademark'].num_nodes
    
    # í…ì„œ ìƒì„±
    indices_ct = edge_ct
    values_ct = torch.ones(edge_ct.size(1))
    adj_ct = torch.sparse_coo_tensor(indices_ct, values_ct, (n_comp, n_tm))
    
    # í–‰ë ¬ B: Trademark -> Class
    edge_tc = data['trademark', 'belongs_to', 'class'].edge_index
    n_class = len(class_names)
    
    indices_tc = edge_tc
    values_tc = torch.ones(edge_tc.size(1))
    adj_tc = torch.sparse_coo_tensor(indices_tc, values_tc, (n_tm, n_class))
    
    # í–‰ë ¬ ê³± (Brand x Class)
    adj_cc = torch.sparse.mm(adj_ct, adj_tc).to_dense() # [Num_Brand, Num_Class]
    
    # 2. í•œêµ­ ë¸Œëœë“œ ë°ì´í„°ë§Œ ì¶”ì¶œ
    korean_stats = adj_cc[korean_indices] # [Num_Korean_Brands, Num_Class]
    
    # 3. ê° ë¸Œëœë“œì˜ Main Classì™€ ì´ ìƒí‘œ ìˆ˜ í™•ì¸
    brand_main_class_ids = torch.argmax(korean_stats, dim=1) # ê° ë¸Œëœë“œì˜ ì£¼ë ¥ ë¥˜ ID
    brand_total_counts = torch.sum(korean_stats, dim=1)      # ê° ë¸Œëœë“œì˜ ì´ ìƒí‘œ ìˆ˜
    
    # 4. ì‚°ì—…êµ°(Class)ë³„ë¡œ ê·¸ë£¹í•‘í•˜ì—¬ 1ë“± ë½‘ê¸°
    # Classë³„ë¡œ (ì´ ìƒí‘œ ìˆ˜, ë¸Œëœë“œ ë¡œì»¬ ì¸ë±ìŠ¤) ë¦¬ìŠ¤íŠ¸ ìƒì„±
    class_leaders = {}
    
    for local_idx, (class_id, count) in enumerate(zip(brand_main_class_ids, brand_total_counts)):
        c_id = class_id.item()
        cnt = count.item()
        if cnt == 0: continue
        
        if c_id not in class_leaders:
            class_leaders[c_id] = []
        class_leaders[c_id].append((cnt, local_idx))
    
    # 5. ê°€ì¥ ì¸ê¸° ìˆëŠ” ì‚°ì—…êµ°(Class) Top-K ì„ ì • (ë¸Œëœë“œê°€ ë§ì´ ëª°ë¦° ë¥˜ ìˆœì„œ)
    # class_leadersì˜ ê¸¸ì´(í•´ë‹¹ ë¥˜ë¥¼ ì£¼ë ¥ìœ¼ë¡œ í•˜ëŠ” ë¸Œëœë“œ ìˆ˜)ë¡œ ì •ë ¬
    popular_classes = sorted(class_leaders.keys(), key=lambda k: len(class_leaders[k]), reverse=True)[:top_k]
    
    final_indices = []
    
    print(f"\nğŸ† [ë‹¤ì–‘ì„± ê¸°ì¤€ Top {top_k} ì„ ì •] ê° ì‚°ì—…êµ° ë³„ 1ìœ„ ë¸Œëœë“œ")
    for c_id in popular_classes:
        # í•´ë‹¹ Class ë‚´ì—ì„œ ìƒí‘œ ìˆ˜ê°€ ê°€ì¥ ë§ì€ ë¸Œëœë“œ 1ê°œ ì„ ì •
        leaders = sorted(class_leaders[c_id], key=lambda x: x[0], reverse=True)
        top_brand_local_idx = leaders[0][1]
        top_brand_count = leaders[0][0]
        
        # ì „ì²´ ì¸ë±ìŠ¤ë¡œ ë³€í™˜
        global_idx = korean_indices[top_brand_local_idx]
        brand_name = comp_names[global_idx]
        class_name = class_names[c_id]
        
        print(f" - [{class_name}ë¥˜ 1ìœ„] {brand_name} (ë³´ìœ : {int(top_brand_count)}ê±´)")
        final_indices.append(global_idx)
        
    return final_indices

# ==========================================
# ğŸ§  ê°­ ë¶„ì„ (Gap Analysis) ì—”ì§„ (ë²„ê·¸ ìˆ˜ì •ë¨)
# ==========================================
def analyze_gap_strategy(data, encoders, brand_idx, top_k=5):
    comp_names = encoders['company_classes']
    class_names = encoders['class_classes']
    group_names = encoders['group_classes']
    brand_name = comp_names[brand_idx]

    # 1. ë‚´ ìƒí‘œ ì°¾ê¸°
    edge_ct = data['company', 'files', 'trademark'].edge_index
    my_tm_mask = (edge_ct[0] == brand_idx)
    my_tm_indices = edge_ct[1][my_tm_mask]

    if len(my_tm_indices) == 0: return None

    # 2. ë‚˜ì˜ ì£¼ë ¥ ë¥˜(Class) ì°¾ê¸°
    edge_tc = data['trademark', 'belongs_to', 'class'].edge_index
    my_cls_mask = torch.isin(edge_tc[0], my_tm_indices)
    my_cls_indices = edge_tc[1][my_cls_mask]
    
    if len(my_cls_indices) == 0: return None
    main_class_idx = torch.mode(my_cls_indices).values.item()
    main_class_name = class_names[main_class_idx]
    
    print(f"\nğŸ¢ [{brand_name}]ì˜ ì£¼ë ¥ ì‚¬ì—…: {main_class_name}ë¥˜")

    # 3. ì£¼ë ¥ ë¥˜ì— ì†í•œ ì „ì²´ ìƒí‘œ ì°¾ê¸°
    class_tm_mask = (edge_tc[1] == main_class_idx)
    global_tm_indices = edge_tc[0][class_tm_mask]
    
    # 4. ì „ì²´ ì‹œì¥ ìœ ì‚¬êµ° í†µê³„
    edge_tg = data['trademark', 'has_code', 'group'].edge_index
    global_group_mask = torch.isin(edge_tg[0], global_tm_indices)
    global_group_indices = edge_tg[1][global_group_mask]
    global_group_counts = torch.bincount(global_group_indices, minlength=len(group_names))
    
    # 5. ë‚´ê°€ ê°€ì§„ ìœ ì‚¬êµ° ì°¾ê¸°
    my_group_mask = torch.isin(edge_tg[0], my_tm_indices)
    my_group_indices = edge_tg[1][my_group_mask]
    my_unique_groups = torch.unique(my_group_indices)
    
    # 6. ê°­ ê³„ì‚°
    candidates = global_group_counts.clone()
    candidates[my_unique_groups] = -1 # ì´ë¯¸ ê°€ì§„ê±´ ì œì™¸
    
    gap_vals, gap_indices = torch.topk(candidates, top_k)
    
    gaps = []
    print(f" ğŸš¨ [ê²½ê³ ] ê²½ìŸì‚¬ë“¤ì€ í™•ë³´í–ˆì§€ë§Œ ê·€ì‚¬ëŠ” ëˆ„ë½ëœ í•µì‹¬ ìœ ì‚¬êµ° (Top {top_k})")
    for idx, count in zip(gap_indices, gap_vals):
        if count.item() <= 0: continue
        g_name = group_names[idx.item()]
        print(f"   ğŸ‘‰ ëˆ„ë½ë¨: {g_name} (ì‹œì¥ ì¶œì› ìˆ˜: {count.item()}ê±´)")
        gaps.append(g_name)
        
    # 7. [ìˆ˜ì •ë¨] ë‚´ê°€ ì˜í•˜ê³  ìˆëŠ” ìœ ì‚¬êµ° (ì•ˆì „í•˜ê²Œ Zip ì‚¬ìš©)
    my_counts = torch.bincount(my_group_indices, minlength=len(group_names))
    # ë‚´ê°€ ê°€ì§„ ê²ƒ ì¤‘ Top 3
    my_strong_indices = torch.argsort(my_counts, descending=True)[:3]
    
    my_strong_groups = []
    for idx in my_strong_indices:
        count = my_counts[idx].item()
        if count > 0:
            my_strong_groups.append(group_names[idx.item()])
    
    return {
        'main_class': main_class_name,
        'gaps': gaps,
        'my_strong': my_strong_groups
    }

# ==========================================
# ğŸ¨ ì‹œê°í™”
# ==========================================
def visualize_gap_analysis(brand_name, analysis_result):
    if not analysis_result: return

    main_class = analysis_result['main_class']
    gaps = analysis_result['gaps']
    my_strong = analysis_result['my_strong']

    G = nx.Graph()
    center_node = f"{main_class}ë¥˜\n(ì£¼ë ¥ì‹œì¥)"
    G.add_node(center_node, type='class', size=3000, color='#FFE66D')
    
    G.add_node(brand_name, type='me', size=2500, color='#FF6B6B')
    G.add_edge(brand_name, center_node, style='solid')
    
    # Safe Zone
    for g_name in my_strong:
        node_id = f"{g_name}\n(ë³´ìœ )"
        G.add_node(node_id, type='safe', size=1500, color='#4ECDC4')
        G.add_edge(center_node, node_id, style='solid', color='gray')
        G.add_edge(brand_name, node_id, style='solid', color='gray')

    # Gap Zone
    for g_name in gaps:
        node_id = f"{g_name}\n(ëˆ„ë½!)"
        G.add_node(node_id, type='gap', size=1800, color='#FF9F1C')
        G.add_edge(center_node, node_id, style='dashed', color='#FF9F1C')

    plt.figure(figsize=(16, 12))
    pos = nx.spring_layout(G, k=0.7, seed=42)
    
    for n, d in G.nodes(data=True):
        nx.draw_networkx_nodes(G, pos, nodelist=[n], node_color=d['color'], node_size=d['size'], alpha=0.9)
    
    edges = G.edges(data=True)
    solid = [(u,v) for u,v,d in edges if d.get('style')=='solid']
    dashed = [(u,v) for u,v,d in edges if d.get('style')=='dashed']
    
    nx.draw_networkx_edges(G, pos, edgelist=solid, width=1.5, edge_color='gray', alpha=0.5)
    nx.draw_networkx_edges(G, pos, edgelist=dashed, width=2.5, edge_color='#FF9F1C', style='dashed')
    
    labels = {n: n for n in G.nodes}
    nx.draw_networkx_labels(G, pos, labels, font_size=10, font_family=GLOBAL_FONT_NAME, font_weight='bold')
    
    legend_elements = [
        Line2D([0], [0], marker='o', color='w', label='Target Brand (ë‚˜)', markerfacecolor='#FF6B6B', markersize=15),
        Line2D([0], [0], marker='o', color='w', label='Main Market (ì£¼ë ¥ ì‹œì¥)', markerfacecolor='#FFE66D', markersize=15),
        Line2D([0], [0], marker='o', color='w', label='Safe Zone (ì´ë¯¸ í™•ë³´í•¨)', markerfacecolor='#4ECDC4', markersize=12),
        Line2D([0], [0], marker='o', color='w', label='GAP / RISK (ëˆ„ë½ëœ ìœ ì‚¬êµ°)', markerfacecolor='#FF9F1C', markersize=15),
        Line2D([0], [0], color='gray', lw=1, label='Existing Link'),
        Line2D([0], [0], color='#FF9F1C', lw=2, linestyle='--', label='Market Trend (ë‚˜ëŠ” ì—†ìŒ)')
    ]
    plt.legend(handles=legend_elements, loc='upper left', prop={'size': 11, 'family': GLOBAL_FONT_NAME})

    plt.title(f"Defensive Strategy: {brand_name} (Gap Analysis)", fontsize=16, fontfamily=GLOBAL_FONT_NAME)
    plt.axis('off')
    
    safe_name = "".join([c if c.isalnum() else "_" for c in brand_name])
    save_path = os.path.join(OUTPUT_DIR, f"KR_GapAnalysis_{safe_name}.png")
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"ğŸ–¼ï¸ ë°©ì–´ ì „ëµ ì§€ë„ ì €ì¥: {save_path}")
    plt.close()

if __name__ == "__main__":
    init_font()
    data, encoders = load_resources()
    
    # [ë³€ê²½ëœ í•¨ìˆ˜ í˜¸ì¶œ]
    top_indices = get_diverse_top_korean_brands(data, encoders, top_k=5)
    
    print("\nğŸš€ [AI ë°©ì–´ ì „ëµ ìˆ˜ë¦½] ê°­ ë¶„ì„(Gap Analysis) ì‹œì‘")
    
    for idx in top_indices:
        brand_name = encoders['company_classes'][idx]
        
        # 2. ê°­ ë¶„ì„ ì‹¤í–‰
        result = analyze_gap_strategy(data, encoders, idx, top_k=5)
        
        # 3. ì‹œê°í™”
        visualize_gap_analysis(brand_name, result)
        
    print("\nâœ… ëª¨ë“  ë¶„ì„ ì™„ë£Œ. ./outputs/graph/gnn í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”.")