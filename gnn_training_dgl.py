import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import dgl
import dgl.nn as dglnn
import dgl.function as fn
from sklearn.metrics import roc_auc_score
from tqdm import tqdm

# ==========================================
# âš™ï¸ ì„¤ì • (Settings)
# ==========================================
PYG_GRAPH_PATH = "./outputs/graph/pet_graph_data.pt"   # ì›ë³¸ PyG ë°ì´í„° ê²½ë¡œ
DGL_GRAPH_PATH = "./outputs/graph/pet_graph_dgl.bin"   # ë³€í™˜ëœ DGL ë°ì´í„° ì €ì¥ ê²½ë¡œ
MODEL_SAVE_PATH = "./outputs/graph/dgl_gnn_model.pth"  # í•™ìŠµëœ ëª¨ë¸ ì €ì¥ ê²½ë¡œ
EMBEDDING_SAVE_PATH = "./outputs/graph/dgl_node_embeddings.pt" # ì„ë² ë”© ë²¡í„° ì €ì¥ ê²½ë¡œ

HIDDEN_DIMS = 64   # ì„ë² ë”© ì°¨ì› í¬ê¸°
EPOCHS = 500        # í•™ìŠµ ë°˜ë³µ íšŸìˆ˜
LR = 0.001         # í•™ìŠµë¥ 

# ==========================================
# ğŸ› ï¸ ë°ì´í„° ë¡œë“œ ë° ë³€í™˜ ìœ í‹¸ë¦¬í‹°
# ==========================================
def convert_pyg_to_dgl(pyg_path):
    """PyG ë°ì´í„°ë¥¼ ì½ì–´ DGL ê·¸ë˜í”„ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    print("ğŸ”„ PyG ë°ì´í„° ë¡œë“œ ë° DGL ë³€í™˜ ì‹œì‘ (ìµœì´ˆ 1íšŒ ì‹¤í–‰)...")
    try:
        pyg_data = torch.load(pyg_path, weights_only=False)
    except TypeError:
        pyg_data = torch.load(pyg_path)
    
    data_dict = {}
    num_nodes_dict = {ntype: pyg_data[ntype].num_nodes for ntype in pyg_data.node_types}

    for edge_type in pyg_data.edge_types:
        src_type, rel, dst_type = edge_type
        edge_index = pyg_data[edge_type].edge_index
        src = edge_index[0].cpu().numpy()
        dst = edge_index[1].cpu().numpy()
        data_dict[(src_type, rel, dst_type)] = (src, dst)

    g = dgl.heterograph(data_dict, num_nodes_dict=num_nodes_dict)
    return g

def get_dgl_graph(force_reload=False):
    if os.path.exists(DGL_GRAPH_PATH) and not force_reload:
        print(f"âœ… ìºì‹œëœ DGL ê·¸ë˜í”„ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤: {DGL_GRAPH_PATH}")
        g_list, _ = dgl.load_graphs(DGL_GRAPH_PATH)
        return g_list[0]
    else:
        if not os.path.exists(PYG_GRAPH_PATH):
            raise FileNotFoundError(f"âŒ ì›ë³¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤: {PYG_GRAPH_PATH}")
        g = convert_pyg_to_dgl(PYG_GRAPH_PATH)
        print(f"ğŸ’¾ DGL ê·¸ë˜í”„ë¥¼ ìºì‹±í•©ë‹ˆë‹¤: {DGL_GRAPH_PATH}")
        os.makedirs(os.path.dirname(DGL_GRAPH_PATH), exist_ok=True)
        dgl.save_graphs(DGL_GRAPH_PATH, [g])
        return g

# ==========================================
# ğŸ§  GNN ëª¨ë¸ ì •ì˜ (Hetero GraphSAGE)
# ==========================================
class HeteroSAGE(nn.Module):
    def __init__(self, g, in_feats, h_feats, out_feats):
        super().__init__()
        self.node_embeddings = nn.ModuleDict()
        for ntype in g.ntypes:
            self.node_embeddings[ntype] = nn.Embedding(g.num_nodes(ntype), in_feats)
        
        self.conv1 = dglnn.HeteroGraphConv({
            etype: dglnn.SAGEConv(in_feats, h_feats, 'mean')
            for etype in g.etypes
        }, aggregate='sum')
        
        self.conv2 = dglnn.HeteroGraphConv({
            etype: dglnn.SAGEConv(h_feats, out_feats, 'mean')
            for etype in g.etypes
        }, aggregate='sum')

    def forward(self, g, x_dict=None):
        # 1. ì´ˆê¸° ì„ë² ë”© ë¡œë“œ
        if x_dict is None:
            x_dict = {ntype: emb.weight for ntype, emb in self.node_embeddings.items()}
        
        # 2. ì²« ë²ˆì§¸ ë ˆì´ì–´ í†µê³¼
        h1 = self.conv1(g, x_dict)
        
        # [í•µì‹¬ ìˆ˜ì •] ì‚¬ë¼ì§„ ë…¸ë“œ ë³µêµ¬ (Residual Connection)
        # íšŒì‚¬ ë…¸ë“œì²˜ëŸ¼ ë“¤ì–´ì˜¤ëŠ” ì—£ì§€ê°€ ì—†ëŠ” ê²½ìš° h1ì— í¬í•¨ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ, ì›ë˜ ê°’ì„ ë„£ì–´ì¤ë‹ˆë‹¤.
        for ntype in x_dict:
            if ntype not in h1:
                h1[ntype] = x_dict[ntype]
        
        h1 = {k: F.leaky_relu(v) for k, v in h1.items()}
        
        # 3. ë‘ ë²ˆì§¸ ë ˆì´ì–´ í†µê³¼
        h2 = self.conv2(g, h1)
        
        # [í•µì‹¬ ìˆ˜ì •] 2ì°¨ ë³µêµ¬
        for ntype in h1:
            if ntype not in h2:
                h2[ntype] = h1[ntype]
                
        return h2

class ScorePredictor(nn.Module):
    """íŠ¹ì • íƒ€ê²Ÿ ì—£ì§€ì— ëŒ€í•´ì„œë§Œ ì ìˆ˜ ê³„ì‚°"""
    def forward(self, edge_subgraph, x, target_etype):
        with edge_subgraph.local_scope():
            src_type, _, dst_type = target_etype
            
            # í•„ìš”í•œ ë…¸ë“œ íƒ€ì… ë°ì´í„° í• ë‹¹ (ì•ˆì „ì¥ì¹˜ ì¶”ê°€)
            if src_type in edge_subgraph.ntypes:
                edge_subgraph.nodes[src_type].data['x'] = x[src_type]
            if dst_type in edge_subgraph.ntypes:
                edge_subgraph.nodes[dst_type].data['x'] = x[dst_type]

            # íƒ€ê²Ÿ ì—£ì§€ì— ëŒ€í•´ì„œë§Œ ì—°ì‚°
            edge_subgraph.apply_edges(fn.u_dot_v('x', 'x', 'score'), etype=target_etype)
            return edge_subgraph.edges[target_etype].data['score']

# ==========================================
# ğŸš€ ë©”ì¸ ì‹¤í–‰ë¶€
# ==========================================
if __name__ == "__main__":
    g = get_dgl_graph()
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"âš¡ í•™ìŠµ ì¥ì¹˜: {device}")
    
    g = g.to(device)

    target_etype = ('company', 'files', 'trademark')
    if target_etype not in g.canonical_etypes:
        # ë°ì´í„°ì…‹ë§ˆë‹¤ ì—£ì§€ ì´ë¦„ì´ ë‹¤ë¥¼ ìˆ˜ ìˆì–´ ìœ ì—°í•˜ê²Œ ì²˜ë¦¬
        target_etype = g.canonical_etypes[0]
    
    print(f"ğŸ¯ í•™ìŠµ íƒ€ê²Ÿ ì—£ì§€: {target_etype}")

    model = HeteroSAGE(g, HIDDEN_DIMS, HIDDEN_DIMS, HIDDEN_DIMS).to(device)
    pred = ScorePredictor().to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=LR)

    print("\nğŸš€ DGL GNN í•™ìŠµ ì‹œì‘...")
    
    for epoch in range(1, EPOCHS + 1):
        model.train()
        
        # --- Negative Sampling ---
        src_node_count = g.num_nodes(target_etype[0])
        dst_node_count = g.num_nodes(target_etype[2])
        num_edges = g.num_edges(target_etype)
        
        neg_src = torch.randint(0, src_node_count, (num_edges,), device=device)
        neg_dst = torch.randint(0, dst_node_count, (num_edges,), device=device)
        
        neg_g = dgl.heterograph(
            {target_etype: (neg_src, neg_dst)},
            num_nodes_dict={nt: g.num_nodes(nt) for nt in g.ntypes}
        ).to(device)

        # --- Forward Pass ---
        h = model(g)
        
        # ìˆ˜ì •ëœ ScorePredictor í˜¸ì¶œ (ì¸ì 3ê°œ)
        pos_score = pred(g, h, target_etype)
        neg_score = pred(neg_g, h, target_etype)
        
        # --- Loss ---
        scores = torch.cat([pos_score, neg_score])
        labels = torch.cat([torch.ones_like(pos_score), torch.zeros_like(neg_score)])
        loss = F.binary_cross_entropy_with_logits(scores, labels)
        
        # --- Backward ---
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        # --- AUC í‰ê°€ ---
        if epoch % 5 == 0 or epoch == 1:
            with torch.no_grad():
                # AUC ê³„ì‚° ì‹œ CPUë¡œ ì´ë™
                auc = roc_auc_score(labels.cpu().numpy(), scores.sigmoid().cpu().numpy())
                print(f"Epoch: {epoch:03d}/{EPOCHS}, Loss: {loss.item():.4f}, AUC: {auc:.4f}")

    print("\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...")
    os.makedirs(os.path.dirname(MODEL_SAVE_PATH), exist_ok=True)
    torch.save(model.state_dict(), MODEL_SAVE_PATH)
    
    model.eval()
    with torch.no_grad():
        final_h = model(g)
        final_h_cpu = {k: v.cpu() for k, v in final_h.items()}
        torch.save(final_h_cpu, EMBEDDING_SAVE_PATH)
        
    print(f"âœ… í•™ìŠµ ì™„ë£Œ!")
    print(f" - ëª¨ë¸: {MODEL_SAVE_PATH}")
    print(f" - ì„ë² ë”©: {EMBEDDING_SAVE_PATH}")